{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd987e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('5dataSeH_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf301b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(186, 3991)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b993cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from testset_prediction import testset_prediction as tsp\n",
    "from sequential_selection import stepwise_selection as sq\n",
    "from loo import loo\n",
    "reg=LinearRegression()\n",
    "\n",
    "def process(tr,trX,Xts,y,yts,seed):\n",
    "    lt=[]\n",
    "    ls=['r2','neg_mean_absolute_error','neg_mean_poisson_deviance','neg_mean_gamma_deviance']\n",
    "    #ls=['r2']\n",
    "    lf=[0,5]\n",
    "    #lf=[0]\n",
    "    l1,l2,l3,l4,l5,l6,l7=[],[],[],[],[],[],[]\n",
    "    for i in ls:\n",
    "        for j in lf:\n",
    "            sqs=sq(trX,y,8,True,True,i,j)\n",
    "            try:\n",
    "               a1,b1=sqs.fit_()\n",
    "               reg.fit(tr[a1],y)\n",
    "               r2tr=reg.score(tr[a1],y)\n",
    "               cv=loo(tr[a1],y,tr)\n",
    "               print(a1)\n",
    "               c,m,l=cv.cal()\n",
    "               r2pr,r2pr2,RMSEP=testpred(Xts[a1],yts,reg,m)\n",
    "               rm2tr,drm2tr=rm2(y,l).fit()\n",
    "               ytspr=pd.DataFrame(reg.predict(Xts[a1]))\n",
    "               rm2ts,drm2ts=rm2(yts,ytspr).fit()\n",
    "            except ValueError:\n",
    "                c=0\n",
    "                r2pr=0\n",
    "                rm2tr=0\n",
    "                rm2ts=0         \n",
    "            #print(c,m,l)\n",
    "            #print(a1)\n",
    "            l1.append(i) \n",
    "            l2.append(j)  \n",
    "            l3.append(c)\n",
    "            l4.append(r2pr)\n",
    "            l6.append(rm2tr)\n",
    "            l7.append(rm2ts)\n",
    "            l5.append(seed)\n",
    "    Dict=dict([('random_seed', l5),('score', l1),('fold', l2),('Q2LOO', l3), ('R2Pred', l4), ('rm2tr', l6), ('rm2ts', l7)])\n",
    "    print(Dict)\n",
    "    table=pd.DataFrame(Dict)\n",
    "    return table\n",
    "    #tbname='Results_table.csv'\n",
    "    #table.to_csv('Results_table.csv',index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44d635d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "def correlation(X,cthreshold):\n",
    "    col_corr = set() # Set of all the names of deleted columns\n",
    "    corr_matrix = X.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if (abs(corr_matrix.iloc[i, j]) > float(cthreshold)) and (corr_matrix.columns[j] not in col_corr):\n",
    "                colname = corr_matrix.columns[i] # getting the name of column\n",
    "                col_corr.add(colname)\n",
    "                if colname in X.columns:\n",
    "                   del X[colname] # deleting the column from the dataset\n",
    "    return X   \n",
    "\n",
    "def variance(X,threshold):\n",
    "    sel = VarianceThreshold(threshold=(threshold* (1 - threshold)))\n",
    "    sel_var=sel.fit_transform(X)\n",
    "    X=X[X.columns[sel.get_support(indices=True)]]    \n",
    "    return X\n",
    "\n",
    "\n",
    "def pretreat(X,cthreshold,vthreshold):\n",
    "    X=correlation(X,cthreshold)\n",
    "    X=variance(X,vthreshold)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1828a877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testpred(Xts,yts,model,trav):\n",
    "    ytspr=pd.DataFrame(model.predict(Xts))\n",
    "    ytspr.columns=['Pred']\n",
    "    tsdf=pd.concat([yts,pd.DataFrame(ytspr)],axis=1)\n",
    "    tsdf.columns=['Active','Predict']\n",
    "    tsdf['Aver']=trav\n",
    "    tsdf['Aver2']=tsdf['Predict'].mean()\n",
    "    tsdf['diff']=tsdf['Active']-tsdf['Predict']\n",
    "    tsdf['diff2']=tsdf['Active']-tsdf['Aver']\n",
    "    tsdf['diff3']=tsdf['Active']-tsdf['Aver2']\n",
    "    r2pr=1-((tsdf['diff']**2).sum()/(tsdf['diff2']**2).sum())\n",
    "    r2pr2=1-((tsdf['diff']**2).sum()/(tsdf['diff3']**2).sum())\n",
    "    RMSEP=((tsdf['diff']**2).sum()/tsdf.shape[0])**0.5\n",
    "    return r2pr,r2pr2,RMSEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb2acee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X=df.iloc[:,2:]\n",
    "Xpt=pretreat(X,0.99,0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63199b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amitc\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['Del_Res']=dataf[self.y.columns[0]]-dataf['Pred_loo']\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['aver']=dataf[self.y.columns[0]].mean()\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['nsum']=dataf[self.y.columns[0]]-dataf['aver']\n",
      "C:\\Users\\amitc\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['Del_Res']=dataf[self.y.columns[0]]-dataf['Pred_loo']\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['aver']=dataf[self.y.columns[0]].mean()\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['nsum']=dataf[self.y.columns[0]]-dataf['aver']\n",
      "C:\\Users\\amitc\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['Del_Res']=dataf[self.y.columns[0]]-dataf['Pred_loo']\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['aver']=dataf[self.y.columns[0]].mean()\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['nsum']=dataf[self.y.columns[0]]-dataf['aver']\n",
      "C:\\Users\\amitc\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['Del_Res']=dataf[self.y.columns[0]]-dataf['Pred_loo']\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['aver']=dataf[self.y.columns[0]].mean()\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['nsum']=dataf[self.y.columns[0]]-dataf['aver']\n",
      "C:\\Users\\amitc\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['Del_Res']=dataf[self.y.columns[0]]-dataf['Pred_loo']\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['aver']=dataf[self.y.columns[0]].mean()\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['nsum']=dataf[self.y.columns[0]]-dataf['aver']\n",
      "C:\\Users\\amitc\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['Del_Res']=dataf[self.y.columns[0]]-dataf['Pred_loo']\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['aver']=dataf[self.y.columns[0]].mean()\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['nsum']=dataf[self.y.columns[0]]-dataf['aver']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amitc\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['Del_Res']=dataf[self.y.columns[0]]-dataf['Pred_loo']\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['aver']=dataf[self.y.columns[0]].mean()\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['nsum']=dataf[self.y.columns[0]]-dataf['aver']\n",
      "C:\\Users\\amitc\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['Del_Res']=dataf[self.y.columns[0]]-dataf['Pred_loo']\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['aver']=dataf[self.y.columns[0]].mean()\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['nsum']=dataf[self.y.columns[0]]-dataf['aver']\n",
      "C:\\Users\\amitc\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['Del_Res']=dataf[self.y.columns[0]]-dataf['Pred_loo']\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['aver']=dataf[self.y.columns[0]].mean()\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['nsum']=dataf[self.y.columns[0]]-dataf['aver']\n",
      "C:\\Users\\amitc\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['Del_Res']=dataf[self.y.columns[0]]-dataf['Pred_loo']\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['aver']=dataf[self.y.columns[0]].mean()\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['nsum']=dataf[self.y.columns[0]]-dataf['aver']\n",
      "C:\\Users\\amitc\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['Del_Res']=dataf[self.y.columns[0]]-dataf['Pred_loo']\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['aver']=dataf[self.y.columns[0]].mean()\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['nsum']=dataf[self.y.columns[0]]-dataf['aver']\n",
      "C:\\Users\\amitc\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['Del_Res']=dataf[self.y.columns[0]]-dataf['Pred_loo']\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['aver']=dataf[self.y.columns[0]].mean()\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['nsum']=dataf[self.y.columns[0]]-dataf['aver']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amitc\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['Del_Res']=dataf[self.y.columns[0]]-dataf['Pred_loo']\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['aver']=dataf[self.y.columns[0]].mean()\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['nsum']=dataf[self.y.columns[0]]-dataf['aver']\n",
      "C:\\Users\\amitc\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['Del_Res']=dataf[self.y.columns[0]]-dataf['Pred_loo']\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['aver']=dataf[self.y.columns[0]].mean()\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['nsum']=dataf[self.y.columns[0]]-dataf['aver']\n",
      "C:\\Users\\amitc\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['Del_Res']=dataf[self.y.columns[0]]-dataf['Pred_loo']\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['aver']=dataf[self.y.columns[0]].mean()\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['nsum']=dataf[self.y.columns[0]]-dataf['aver']\n",
      "C:\\Users\\amitc\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['Del_Res']=dataf[self.y.columns[0]]-dataf['Pred_loo']\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['aver']=dataf[self.y.columns[0]].mean()\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['nsum']=dataf[self.y.columns[0]]-dataf['aver']\n",
      "C:\\Users\\amitc\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['Del_Res']=dataf[self.y.columns[0]]-dataf['Pred_loo']\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['aver']=dataf[self.y.columns[0]].mean()\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['nsum']=dataf[self.y.columns[0]]-dataf['aver']\n",
      "C:\\Users\\amitc\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['Del_Res']=dataf[self.y.columns[0]]-dataf['Pred_loo']\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['aver']=dataf[self.y.columns[0]].mean()\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['nsum']=dataf[self.y.columns[0]]-dataf['aver']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amitc\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['Del_Res']=dataf[self.y.columns[0]]-dataf['Pred_loo']\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['aver']=dataf[self.y.columns[0]].mean()\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['nsum']=dataf[self.y.columns[0]]-dataf['aver']\n",
      "C:\\Users\\amitc\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['Del_Res']=dataf[self.y.columns[0]]-dataf['Pred_loo']\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['aver']=dataf[self.y.columns[0]].mean()\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['nsum']=dataf[self.y.columns[0]]-dataf['aver']\n",
      "C:\\Users\\amitc\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['Del_Res']=dataf[self.y.columns[0]]-dataf['Pred_loo']\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['aver']=dataf[self.y.columns[0]].mean()\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['nsum']=dataf[self.y.columns[0]]-dataf['aver']\n",
      "C:\\Users\\amitc\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['Del_Res']=dataf[self.y.columns[0]]-dataf['Pred_loo']\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['aver']=dataf[self.y.columns[0]].mean()\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['nsum']=dataf[self.y.columns[0]]-dataf['aver']\n",
      "C:\\Users\\amitc\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['Del_Res']=dataf[self.y.columns[0]]-dataf['Pred_loo']\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['aver']=dataf[self.y.columns[0]].mean()\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['nsum']=dataf[self.y.columns[0]]-dataf['aver']\n",
      "C:\\Users\\amitc\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['Del_Res']=dataf[self.y.columns[0]]-dataf['Pred_loo']\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['aver']=dataf[self.y.columns[0]].mean()\n",
      "C:\\Users\\amitc\\Documents\\subham_work\\SFS-QSAR-tool-master\\loo.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataf['nsum']=dataf[self.y.columns[0]]-dataf['aver']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "Xpt2=Xpt.columns.tolist()[1:]\n",
    "perc=20\n",
    "nls=[]\n",
    "for sp in range(2,5):\n",
    "    #perc=int(secondEntryTabOne.get())\n",
    "    pc=int(100/perc)\n",
    "    #sp=int(secondEntryTabOne_x.get())\n",
    "    filem=df.sort_values(df.iloc[:,1:2].columns[0],ascending=False)\n",
    "    ts=filem.iloc[(sp-1)::pc, :]\n",
    "    tr=filem.drop(ts.index.values)\n",
    "    #tr.to_csv('tr.csv', index=False)\n",
    "    #a,b= train_test_split(df,test_size=perc, random_state=i)\n",
    "    #tr=pd.DataFrame(a)\n",
    "    #ts=pd.DataFrame(b)\n",
    "    tr=tr.reset_index().drop('index', axis=1)\n",
    "    ts=ts.reset_index().drop('index', axis=1)\n",
    "    trX=tr[Xpt2]\n",
    "    Xts=ts[Xpt2]\n",
    "    #print(trX.shape)\n",
    "    y=tr.iloc[:,1:2]\n",
    "    tr1=pd.concat([tr.iloc[:,0:2],trX],axis=1)\n",
    "    ts1=pd.concat([ts.iloc[:,0:2],Xts],axis=1)\n",
    "    #tr1.to_csv('tr.csv', index=False)\n",
    "    #ts1.to_csv('ts.csv', index=False)\n",
    "    yts=ts.iloc[:,1:2] \n",
    "    table=process(tr,trX,Xts,y,yts,sp)\n",
    "    nls.append(table)\n",
    "    fd=pd.concat(nls, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d830761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_point</th>\n",
       "      <th>score</th>\n",
       "      <th>fold</th>\n",
       "      <th>Q2LOO</th>\n",
       "      <th>R2Pred</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>neg_mean_poisson_deviance</td>\n",
       "      <td>0</td>\n",
       "      <td>0.709382</td>\n",
       "      <td>0.562686</td>\n",
       "      <td>0.636034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>r2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.709382</td>\n",
       "      <td>0.562686</td>\n",
       "      <td>0.636034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>neg_mean_absolute_error</td>\n",
       "      <td>5</td>\n",
       "      <td>0.587652</td>\n",
       "      <td>0.527151</td>\n",
       "      <td>0.557402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>r2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.714010</td>\n",
       "      <td>0.317279</td>\n",
       "      <td>0.515644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>neg_mean_gamma_deviance</td>\n",
       "      <td>5</td>\n",
       "      <td>0.725024</td>\n",
       "      <td>0.260477</td>\n",
       "      <td>0.492750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>neg_mean_absolute_error</td>\n",
       "      <td>5</td>\n",
       "      <td>0.313697</td>\n",
       "      <td>0.651372</td>\n",
       "      <td>0.482534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>neg_mean_gamma_deviance</td>\n",
       "      <td>5</td>\n",
       "      <td>0.657342</td>\n",
       "      <td>0.253554</td>\n",
       "      <td>0.455448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>neg_mean_poisson_deviance</td>\n",
       "      <td>5</td>\n",
       "      <td>0.657342</td>\n",
       "      <td>0.253554</td>\n",
       "      <td>0.455448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>neg_mean_absolute_error</td>\n",
       "      <td>0</td>\n",
       "      <td>0.704509</td>\n",
       "      <td>0.190100</td>\n",
       "      <td>0.447305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>r2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.707002</td>\n",
       "      <td>0.185993</td>\n",
       "      <td>0.446498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>neg_mean_gamma_deviance</td>\n",
       "      <td>0</td>\n",
       "      <td>0.708962</td>\n",
       "      <td>0.117228</td>\n",
       "      <td>0.413095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>neg_mean_poisson_deviance</td>\n",
       "      <td>0</td>\n",
       "      <td>0.708962</td>\n",
       "      <td>0.117228</td>\n",
       "      <td>0.413095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>neg_mean_poisson_deviance</td>\n",
       "      <td>5</td>\n",
       "      <td>0.623659</td>\n",
       "      <td>0.190977</td>\n",
       "      <td>0.407318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>r2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.490511</td>\n",
       "      <td>0.313765</td>\n",
       "      <td>0.402138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>neg_mean_gamma_deviance</td>\n",
       "      <td>5</td>\n",
       "      <td>0.635613</td>\n",
       "      <td>0.065085</td>\n",
       "      <td>0.350349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>r2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.215703</td>\n",
       "      <td>0.431689</td>\n",
       "      <td>0.323696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>neg_mean_absolute_error</td>\n",
       "      <td>0</td>\n",
       "      <td>0.630166</td>\n",
       "      <td>-0.082465</td>\n",
       "      <td>0.273850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>neg_mean_gamma_deviance</td>\n",
       "      <td>0</td>\n",
       "      <td>0.704910</td>\n",
       "      <td>-0.255527</td>\n",
       "      <td>0.224691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>neg_mean_absolute_error</td>\n",
       "      <td>5</td>\n",
       "      <td>0.571908</td>\n",
       "      <td>-0.227302</td>\n",
       "      <td>0.172303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>neg_mean_absolute_error</td>\n",
       "      <td>0</td>\n",
       "      <td>0.675712</td>\n",
       "      <td>-0.647229</td>\n",
       "      <td>0.014241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>neg_mean_poisson_deviance</td>\n",
       "      <td>5</td>\n",
       "      <td>0.671021</td>\n",
       "      <td>-0.798557</td>\n",
       "      <td>-0.063768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>neg_mean_gamma_deviance</td>\n",
       "      <td>0</td>\n",
       "      <td>0.766462</td>\n",
       "      <td>-0.987728</td>\n",
       "      <td>-0.110633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>neg_mean_poisson_deviance</td>\n",
       "      <td>0</td>\n",
       "      <td>0.766462</td>\n",
       "      <td>-0.987728</td>\n",
       "      <td>-0.110633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>r2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.240996</td>\n",
       "      <td>-0.487768</td>\n",
       "      <td>-0.123386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_point                      score  fold     Q2LOO    R2Pred   Average\n",
       "4            4  neg_mean_poisson_deviance     0  0.709382  0.562686  0.636034\n",
       "0            4                         r2     0  0.709382  0.562686  0.636034\n",
       "3            3    neg_mean_absolute_error     5  0.587652  0.527151  0.557402\n",
       "0            3                         r2     0  0.714010  0.317279  0.515644\n",
       "7            2    neg_mean_gamma_deviance     5  0.725024  0.260477  0.492750\n",
       "3            4    neg_mean_absolute_error     5  0.313697  0.651372  0.482534\n",
       "7            4    neg_mean_gamma_deviance     5  0.657342  0.253554  0.455448\n",
       "5            4  neg_mean_poisson_deviance     5  0.657342  0.253554  0.455448\n",
       "2            4    neg_mean_absolute_error     0  0.704509  0.190100  0.447305\n",
       "0            2                         r2     0  0.707002  0.185993  0.446498\n",
       "6            3    neg_mean_gamma_deviance     0  0.708962  0.117228  0.413095\n",
       "4            3  neg_mean_poisson_deviance     0  0.708962  0.117228  0.413095\n",
       "5            3  neg_mean_poisson_deviance     5  0.623659  0.190977  0.407318\n",
       "1            3                         r2     5  0.490511  0.313765  0.402138\n",
       "7            3    neg_mean_gamma_deviance     5  0.635613  0.065085  0.350349\n",
       "1            4                         r2     5  0.215703  0.431689  0.323696\n",
       "2            3    neg_mean_absolute_error     0  0.630166 -0.082465  0.273850\n",
       "6            4    neg_mean_gamma_deviance     0  0.704910 -0.255527  0.224691\n",
       "3            2    neg_mean_absolute_error     5  0.571908 -0.227302  0.172303\n",
       "2            2    neg_mean_absolute_error     0  0.675712 -0.647229  0.014241\n",
       "5            2  neg_mean_poisson_deviance     5  0.671021 -0.798557 -0.063768\n",
       "6            2    neg_mean_gamma_deviance     0  0.766462 -0.987728 -0.110633\n",
       "4            2  neg_mean_poisson_deviance     0  0.766462 -0.987728 -0.110633\n",
       "1            2                         r2     5  0.240996 -0.487768 -0.123386"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd['Average']=fd[['Q2LOO', 'R2Pred']].mean(axis=1)\n",
    "fd.sort_values('Average', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68927641",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
